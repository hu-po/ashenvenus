{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import glob\n",
    "import PIL.Image as Image\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from tqdm import tqdm\n",
    "from ipywidgets import interact, fixed\n",
    "\n",
    "PREFIX = 'data/train/1/'\n",
    "BUFFER = 30  # Buffer size in x and y direction\n",
    "Z_START = 27 # First slice in the z direction to use\n",
    "Z_DIM = 10   # Number of slices in the z direction\n",
    "TRAINING_STEPS = 100\n",
    "LEARNING_RATE = 0.03\n",
    "BATCH_SIZE = 32\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "plt.imshow(Image.open(PREFIX+\"ir.png\"), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.array(Image.open(PREFIX+\"mask.png\").convert('1'))\n",
    "label = torch.from_numpy(np.array(Image.open(PREFIX+\"inklabels.png\"))).gt(0).float().to(DEVICE)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.set_title(\"mask.png\")\n",
    "ax1.imshow(mask, cmap='gray')\n",
    "ax2.set_title(\"inklabels.png\")\n",
    "ax2.imshow(label.cpu(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 3d x-ray scan, one slice at a time\n",
    "images = [np.array(Image.open(filename), dtype=np.float32)/65535.0 for filename in tqdm(sorted(glob.glob(PREFIX+\"surface_volume/*.tif\"))[Z_START:Z_START+Z_DIM])]\n",
    "image_stack = torch.stack([torch.from_numpy(image) for image in images], dim=0).to(DEVICE)\n",
    "\n",
    "fig, axes = plt.subplots(1, len(images), figsize=(15, 3))\n",
    "for image, ax in zip(images, axes):\n",
    "  ax.imshow(np.array(Image.fromarray(image).resize((image.shape[1]//20, image.shape[0]//20)), dtype=np.float32), cmap='gray')\n",
    "  ax.set_xticks([]); ax.set_yticks([])\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rect = (1100, 3500, 700, 950)\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(label.cpu())\n",
    "patch = patches.Rectangle((rect[0], rect[1]), rect[2], rect[3], linewidth=2, edgecolor='r', facecolor='none')\n",
    "ax.add_patch(patch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubvolumeDataset(data.Dataset):\n",
    "    def __init__(self, image_stack, label, pixels):\n",
    "        self.image_stack = image_stack\n",
    "        self.label = label\n",
    "        self.pixels = pixels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pixels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        y, x = self.pixels[index]\n",
    "        subvolume = self.image_stack[:, y-BUFFER:y+BUFFER+1, x -\n",
    "                                     BUFFER:x+BUFFER+1].view(1, Z_DIM, BUFFER*2+1, BUFFER*2+1)\n",
    "        inklabel = self.label[y, x].view(1)\n",
    "        return subvolume, inklabel\n",
    "\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv3d(1, 16, 3, 1, 1),\n",
    "    nn.MaxPool3d(2, 2),\n",
    "    nn.Conv3d(16, 32, 3, 1, 1),\n",
    "    nn.MaxPool3d(2, 2),\n",
    "    nn.Conv3d(32, 64, 3, 1, 1),\n",
    "    nn.MaxPool3d(2, 2),\n",
    "    nn.Flatten(start_dim=1),\n",
    "    nn.LazyLinear(128),\n",
    "    nn.ReLU(),\n",
    "    nn.LazyLinear(1),\n",
    "    nn.Sigmoid()\n",
    ").to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating pixel lists...\")\n",
    "# Split our dataset into train and val. The pixels inside the rect are the \n",
    "# val set, and the pixels outside the rect are the train set.\n",
    "pixels_inside_rect = []\n",
    "pixels_outside_rect = []\n",
    "for pixel in zip(*np.where(mask == 1)):\n",
    "    if pixel[1] < BUFFER or pixel[1] >= mask.shape[1]-BUFFER or pixel[0] < BUFFER or pixel[0] >= mask.shape[0]-BUFFER:\n",
    "        continue # Too close to the edge\n",
    "    if pixel[1] >= rect[0] and pixel[1] <= rect[0]+rect[2] and pixel[0] >= rect[1] and pixel[0] <= rect[1]+rect[3]:\n",
    "        pixels_inside_rect.append(pixel)\n",
    "    else:\n",
    "        pixels_outside_rect.append(pixel)\n",
    "\n",
    "print(\"Training...\")\n",
    "train_dataset = SubvolumeDataset(image_stack, label, pixels_outside_rect)\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=LEARNING_RATE, total_steps=TRAINING_STEPS)\n",
    "model.train()\n",
    "running_loss = 0.0\n",
    "for i, (subvolumes, inklabels) in tqdm(enumerate(train_loader), total=TRAINING_STEPS):\n",
    "    if i >= TRAINING_STEPS:\n",
    "        break\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(subvolumes.to(DEVICE))\n",
    "    loss = criterion(outputs, inklabels.to(DEVICE))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    running_loss += loss.item()\n",
    "    if i % 3000 == 3000-1:\n",
    "        print(\"Loss:\", running_loss / 3000)\n",
    "        running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = SubvolumeDataset(image_stack, label, pixels_inside_rect)\n",
    "eval_loader = data.DataLoader(eval_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "output = torch.zeros_like(label).float()\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, (subvolumes, _) in enumerate(tqdm(eval_loader)):\n",
    "        for j, value in enumerate(model(subvolumes.to(DEVICE))):\n",
    "            output[pixels_inside_rect[i*BATCH_SIZE+j]] = value\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(output.cpu(), cmap='gray')\n",
    "ax2.imshow(label.cpu(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.4\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(output.gt(THRESHOLD).cpu(), cmap='gray')\n",
    "ax2.imshow(label.cpu(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import rle\n",
    "\n",
    "rle_output = rle(output)\n",
    "print(\"Id,Predicted\\na,\" + rle_output + \"\\nb,\" + rle_output, file=open('submission.csv', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ashenvenus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "59e02e9fd9b54cac904af6e64a4aca1dfa97a1ffc2c4ef530ec9aa5e2e25eb58"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
