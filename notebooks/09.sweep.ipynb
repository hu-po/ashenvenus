{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import gc\n",
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torch.utils.data as data\n",
    "from PIL import Image, ImageFilter\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from torchvision import transforms\n",
    "from torchvision.models import (ConvNeXt_Tiny_Weights, ResNeXt50_32X4D_Weights,\n",
    "                                Swin_T_Weights, ViT_B_32_Weights,\n",
    "                                convnext_tiny, resnext50_32x4d, swin_t,\n",
    "                                vit_b_32)\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class PatchDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        # Directory containing the datasets\n",
    "        data_dir: str,\n",
    "        # Expected slices per fragment\n",
    "        slice_depth: int = 4,\n",
    "        # Size of an individual patch\n",
    "        patch_size_x: int = 1028,\n",
    "        patch_size_y: int = 256,\n",
    "        # Image resize ratio\n",
    "        resize_ratio: float = 1.0,\n",
    "        # Training vs Testing mode\n",
    "        train: bool = True,\n",
    "        # Filenames of the images we'll use\n",
    "        image_mask_filename='mask.png',\n",
    "        image_labels_filename='inklabels.png',\n",
    "        slices_dir_filename='surface_volume',\n",
    "    ):\n",
    "        print(f\"Creating CurriculumDataset for {data_dir}\")\n",
    "        # Train mode also loads the labels\n",
    "        self.train = train\n",
    "        # Resize ratio reduces the size of the image\n",
    "        self.resize_ratio = resize_ratio\n",
    "        # Data will be B x slice_depth x patch_size_x x patch_size_y\n",
    "        self.patch_size_x = patch_size_x\n",
    "        self.patch_size_y = patch_size_y\n",
    "        self.patch_size_x_half = int(patch_size_x / 2)\n",
    "        self.patch_size_y_half = int(patch_size_y / 2)\n",
    "        self.slice_depth = slice_depth\n",
    "        assert os.path.exists(\n",
    "            data_dir), f\"Data directory {data_dir} does not exist\"\n",
    "        # Open Mask image\n",
    "        _image_mask_filepath = os.path.join(data_dir, image_mask_filename)\n",
    "        _mask_img = Image.open(_image_mask_filepath).convert(\"1\")\n",
    "        # Get original size and resized size\n",
    "        self.original_size = _mask_img.size\n",
    "        self.resized_size = (\n",
    "            int(self.original_size[0] * self.resize_ratio),\n",
    "            int(self.original_size[1] * self.resize_ratio),\n",
    "        )\n",
    "        # Resize the mask\n",
    "        # print(f\"Mask original size: {original_size}\")\n",
    "        _mask_img = _mask_img.resize(self.resized_size, resample=Image.BILINEAR)\n",
    "        # print(f\"Mask resized size: {_mask_img.size}\")\n",
    "        _mask = torch.from_numpy(np.array(_mask_img)).to(torch.bool)\n",
    "        # print(f\"Mask tensor shape: {_mask.shape}\")\n",
    "        # print(f\"Mask tensor dtype: {_mask.dtype}\")\n",
    "        if train:\n",
    "            _image_labels_filepath = os.path.join(\n",
    "                data_dir, image_labels_filename)\n",
    "            _labels_img = Image.open(_image_labels_filepath).convert(\"1\")\n",
    "            # print(f\"Labels original size: {original_size}\")\n",
    "            _labels_img = _labels_img.resize(\n",
    "                self.resized_size, resample=Image.BILINEAR)\n",
    "            # print(f\"Labels resized size: {_labels_img.size}\")\n",
    "            self.labels = torch.from_numpy(\n",
    "                np.array(_labels_img)).to(torch.bool)\n",
    "            # print(f\"Labels tensor shape: {self.labels.shape}\")\n",
    "            # print(f\"Labels tensor dtype: {self.labels.dtype}\")\n",
    "        # Pre-allocate the entire fragment\n",
    "        self.fragment = torch.zeros((\n",
    "            self.slice_depth,\n",
    "            self.resized_size[1],\n",
    "            self.resized_size[0],\n",
    "        ), dtype=torch.float32\n",
    "        )\n",
    "        # print(f\"Fragment tensor shape: {self.fragment.shape}\")\n",
    "        # print(f\"Fragment tensor dtype: {self.fragment.dtype}\")\n",
    "        # Open up slices\n",
    "        _slice_dir = os.path.join(data_dir, slices_dir_filename)\n",
    "        for i in tqdm(range(self.slice_depth)):\n",
    "            _slice_filepath = os.path.join(_slice_dir, f\"{i:02d}.tif\")\n",
    "            _slice_img = Image.open(_slice_filepath).convert('F')\n",
    "            # print(f\"Slice original size: {original_size}\")\n",
    "            _slice_img = _slice_img.resize(\n",
    "                self.resized_size, resample=Image.BILINEAR)\n",
    "            # print(f\"Slice resized size: {_slice_img.size}\")\n",
    "            _slice = torch.from_numpy(np.array(_slice_img)/65535.0)\n",
    "            # print(f\"Slice tensor shape: {_slice.shape}\")\n",
    "            # print(f\"Slice tensor dtype: {_slice.dtype}\")\n",
    "            self.fragment[i, :, :] = _slice\n",
    "\n",
    "        print(f\"Fragment tensor shape: {self.fragment.shape}\")\n",
    "        print(f\"Fragment tensor dtype: {self.fragment.dtype}\")\n",
    "        print(f\"Fragment tensor min: {self.fragment.min()}\")\n",
    "        print(f\"Fragment tensor max: {self.fragment.max()}\")\n",
    "        # print(f\"Fragment tensor mean: {self.fragment.mean()}\")\n",
    "        # print(f\"Fragment tensor std: {self.fragment.std()}\")\n",
    "\n",
    "        # Get mean/std for fragment only on mask indices\n",
    "        _fragment_mask = _mask.unsqueeze(0).expand(self.slice_depth, -1, -1)\n",
    "        self.mean = self.fragment[_fragment_mask].mean()\n",
    "        self.std = self.fragment[_fragment_mask].std()\n",
    "        # print(f\"Fragment tensor mean (no mask): {self.mean}\")\n",
    "        # print(f\"Fragment tensor std (no mask): {self.std}\")\n",
    "\n",
    "        # Get indices where mask is 1\n",
    "        self.mask_indices = torch.nonzero(_mask).to(torch.int32)\n",
    "        # print(f\"Mask indices shape: {self.mask_indices.shape}\")\n",
    "        # print(f\"Mask indices dtype: {self.mask_indices.dtype}\")\n",
    "\n",
    "        # TODO: Use Predictions to additionally balance the dataset\n",
    "        # if self.train:\n",
    "        #     # Get indices where labels are 1\n",
    "        #     self.labels_indices = torch.nonzero(self.labels).to(torch.int32)\n",
    "        #     # print(f\"Labels indices shape: {self.labels_indices.shape}\")\n",
    "        #     # print(f\"Labels indices dtype: {self.labels_indices.dtype}\")\n",
    "            \n",
    "        #     # Indices where mask is 0 and labels is 1\n",
    "        #     self.mask_0_labels_1_indices = torch.nonzero(\n",
    "        #         (~_mask) & self.labels\n",
    "        #     ).to(torch.int32)\n",
    "\n",
    "        # Pad the fragment with zeros based on patch size\n",
    "        self.fragment = F.pad(\n",
    "            self.fragment,\n",
    "            (\n",
    "                # Padding in Y\n",
    "                self.patch_size_y_half, self.patch_size_y_half,\n",
    "                # Padding in X\n",
    "                self.patch_size_x_half, self.patch_size_x_half,\n",
    "                # No padding on z\n",
    "                0, 0,\n",
    "            ),\n",
    "            mode='constant',\n",
    "            value=0,\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.mask_indices.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        # Get the x, y from the mask indices\n",
    "        x, y = self.mask_indices[index]\n",
    "        # print(f\"Index: {index}, x: {x}, y: {y}\")\n",
    "\n",
    "        # Pre-allocate the patch\n",
    "        patch = self.fragment[\n",
    "                :,\n",
    "                x: x + self.patch_size_x,\n",
    "                y: y + self.patch_size_y,\n",
    "        ]\n",
    "        # print(f\"Patch tensor shape: {patch.shape}\")\n",
    "        # print(f\"Patch tensor dtype: {patch.dtype}\")\n",
    "        # print(f\"Patch tensor min: {patch.min()}\")\n",
    "        # print(f\"Patch tensor max: {patch.max()}\")\n",
    "\n",
    "        # Label is going to be the label of the center voxel\n",
    "        if self.train:\n",
    "            label = self.labels[\n",
    "                x,\n",
    "                y,\n",
    "            ]\n",
    "            return patch, label.unsqueeze(0).to(torch.float32)\n",
    "        else:\n",
    "            # If we're not training, we don't have labels\n",
    "            return patch\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Using GPU\")\n",
    "        return torch.device(\"cuda\")\n",
    "    else:\n",
    "        print(\"Using CPU\")\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "def image_to_rle(img, threshold=0.5):\n",
    "    # TODO: Histogram of image to see where threshold should be\n",
    "    flat_img = img.flatten()\n",
    "    flat_img = np.where(flat_img > threshold, 1, 0).astype(np.uint8)\n",
    "    starts = np.array((flat_img[:-1] == 0) & (flat_img[1:] == 1))\n",
    "    ends = np.array((flat_img[:-1] == 1) & (flat_img[1:] == 0))\n",
    "    starts_ix = np.where(starts)[0] + 2\n",
    "    ends_ix = np.where(ends)[0] + 2\n",
    "    lengths = ends_ix - starts_ix\n",
    "    return starts_ix, lengths\n",
    "\n",
    "def save_rle_as_image(rle_csv_path, output_dir, image_shape):\n",
    "    with open(rle_csv_path, 'r') as csvfile:\n",
    "        csv_reader = csv.reader(csvfile)\n",
    "        next(csv_reader)  # Skip header\n",
    "        for row in csv_reader:\n",
    "            subtest_name, rle_data = row\n",
    "            rle_pairs = list(map(int, rle_data.split()))\n",
    "\n",
    "            # Decode RLE data\n",
    "            img = np.zeros(image_shape[0] * image_shape[1], dtype=np.uint8)\n",
    "            for i in range(0, len(rle_pairs), 2):\n",
    "                start = rle_pairs[i] - 1\n",
    "                end = start + rle_pairs[i + 1]\n",
    "                img[start:end] = 1\n",
    "\n",
    "            # Reshape decoded image data to original shape\n",
    "            img = img.reshape(image_shape)\n",
    "            img = Image.fromarray(img * 255).convert('1')\n",
    "            _image_filepath = os.path.join(output_dir, f\"pred_{subtest_name}_rle.png\")\n",
    "            img.save(_image_filepath)\n",
    "\n",
    "\n",
    "def get_gpu_memory():\n",
    "    result = subprocess.run(['nvidia-smi', '--query-gpu=memory.used,memory.free',\n",
    "                             '--format=csv,nounits,noheader'], stdout=subprocess.PIPE, text=True)\n",
    "    gpu_memory = [tuple(map(int, line.split(',')))\n",
    "                  for line in result.stdout.strip().split('\\n')]\n",
    "    for i, (used, free) in enumerate(gpu_memory):\n",
    "        print(f\"GPU {i}: Memory Used: {used} MiB | Memory Available: {free} MiB\")\n",
    "\n",
    "\n",
    "def clear_gpu_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        print('Clearing GPU memory')\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "class PreTrainNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        slice_depth: int = 65,\n",
    "        pretrained_model: str = 'convnext_tiny',\n",
    "        freeze_backbone: bool = False,\n",
    "        pretrained_weights_filepath: str = None,\n",
    "        use_gelu: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(slice_depth, 3, 3)\n",
    "        if use_gelu:\n",
    "            self.af = nn.GELU()\n",
    "        else:\n",
    "            self.af = nn.ReLU()\n",
    "        # Load pretrained model\n",
    "        if pretrained_model == 'convnext_tiny':\n",
    "            if pretrained_weights_filepath is not None:\n",
    "                self.pre_trained_model = convnext_tiny()\n",
    "            else:\n",
    "                _weights = ConvNeXt_Tiny_Weights.DEFAULT\n",
    "                self.pre_trained_model = convnext_tiny(weights=_weights)\n",
    "        elif pretrained_model == 'vit_b_32':\n",
    "            if pretrained_weights_filepath is not None:\n",
    "                self.pre_trained_model = vit_b_32()\n",
    "            else:\n",
    "                _weights = ViT_B_32_Weights.DEFAULT\n",
    "                self.pre_trained_model = vit_b_32(weights=_weights)\n",
    "        elif pretrained_model == 'swin_t':\n",
    "            if pretrained_weights_filepath is not None:\n",
    "                self.pre_trained_model = swin_t()\n",
    "            else:\n",
    "                _weights = Swin_T_Weights.DEFAULT\n",
    "                self.pre_trained_model = swin_t(weights=_weights)\n",
    "        elif pretrained_model == 'resnext50_32x4d':\n",
    "            if pretrained_weights_filepath is not None:\n",
    "                self.pre_trained_model = resnext50_32x4d()\n",
    "            else:\n",
    "                _weights = ResNeXt50_32X4D_Weights.DEFAULT\n",
    "                self.pre_trained_model = resnext50_32x4d(weights=_weights)\n",
    "        if pretrained_weights_filepath is not None:\n",
    "            _state_dict = torch.load(pretrained_weights_filepath)\n",
    "            self.pre_trained_model.load_state_dict(_state_dict)\n",
    "        # Put model in training mode\n",
    "        if freeze_backbone:\n",
    "            self.pre_trained_model.eval()\n",
    "        else:\n",
    "            self.pre_trained_model.train()\n",
    "        # Binary classification head on top\n",
    "        self.fc = nn.LazyLinear(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.af(self.conv(x))\n",
    "        x = self.pre_trained_model(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        slice_depth: int = 65,\n",
    "        use_gelu: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(slice_depth, 16, 3)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        if use_gelu:\n",
    "            self.af = nn.GELU()\n",
    "        else:\n",
    "            self.af = nn.ReLU()\n",
    "\n",
    "        self.fc1 = nn.LazyLinear(32)\n",
    "        self.fc2 = nn.LazyLinear(64)\n",
    "        self.fc3 = nn.LazyLinear(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.af(self.conv1(x)))\n",
    "        x = self.pool(self.af(self.conv2(x)))\n",
    "        x = self.pool(self.af(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = self.af(self.fc1(x))\n",
    "        x = self.af(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def train_loop(\n",
    "    train_dir: str = \"data/train/\",\n",
    "    eval_dir: str = \"data/eval/\",\n",
    "    model: str = \"simplenet\",\n",
    "    freeze_backbone: bool = False,\n",
    "    pretrained_weights_filepath: str = None,\n",
    "    optimizer: str = \"adam\",\n",
    "    curriculum: str = \"1\",\n",
    "    max_samples_per_dataset: int = 100,\n",
    "    output_dir: str = \"output/train\",\n",
    "    image_augs: bool = False,\n",
    "    use_gelu: bool = False,\n",
    "    slice_depth: int = 3,\n",
    "    patch_size_x: int = 512,\n",
    "    patch_size_y: int = 128,\n",
    "    resize_ratio: float = 1.0,\n",
    "    batch_size: int = 16,\n",
    "    lr: float = 0.001,\n",
    "    lr_scheduling_gamma: float = None,\n",
    "    num_epochs: int = 2,\n",
    "    num_workers: int = 1,\n",
    "    write_logs: bool = False,\n",
    "    save_pred_img: bool = False,\n",
    "    save_submit_csv: bool = False,\n",
    "    save_model: bool = False,\n",
    "    threshold: float = 0.5,\n",
    "    postprocess: bool = True,\n",
    "    max_time_hours: float = 8,\n",
    "):\n",
    "    device = get_device()\n",
    "    clear_gpu_memory()\n",
    "\n",
    "    # Notebook will only run for this amount of time\n",
    "    time_train_max_seconds = max_time_hours * 60 * 60\n",
    "    time_start = time.time()\n",
    "    time_elapsed = 0\n",
    "\n",
    "    # Load the model, try to fit on GPU\n",
    "    if model == \"simplenet\":\n",
    "        model = SimpleNet(\n",
    "            slice_depth=slice_depth,\n",
    "            use_gelu=use_gelu,\n",
    "        )\n",
    "    elif model == 'convnext_tiny':\n",
    "        model = PreTrainNet(\n",
    "            slice_depth=slice_depth,\n",
    "            pretrained_model='convnext_tiny',\n",
    "            freeze_backbone=freeze_backbone,\n",
    "            pretrained_weights_filepath=pretrained_weights_filepath,\n",
    "            use_gelu=use_gelu,\n",
    "        )\n",
    "    elif model == 'vit_b_32':\n",
    "        model = PreTrainNet(\n",
    "            slice_depth=slice_depth,\n",
    "            pretrained_model='vit_b_32',\n",
    "            freeze_backbone=freeze_backbone,\n",
    "            pretrained_weights_filepath=pretrained_weights_filepath,\n",
    "            use_gelu=use_gelu,\n",
    "        )\n",
    "    elif model == 'swin_t':\n",
    "        model = PreTrainNet(\n",
    "            slice_depth=slice_depth,\n",
    "            pretrained_model='swin_t',\n",
    "            freeze_backbone=freeze_backbone,\n",
    "            pretrained_weights_filepath=pretrained_weights_filepath,\n",
    "            use_gelu=use_gelu,\n",
    "        )\n",
    "    elif model == 'resnext50_32x4d':\n",
    "        model = PreTrainNet(\n",
    "            slice_depth=slice_depth,\n",
    "            pretrained_model='resnext50_32x4d',\n",
    "            freeze_backbone=freeze_backbone,\n",
    "            pretrained_weights_filepath=pretrained_weights_filepath,\n",
    "            use_gelu=use_gelu,\n",
    "        )\n",
    "    model = model.to(device)\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Create optimizers\n",
    "    if optimizer == \"adam\":\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    elif optimizer == \"sgd\":\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    if lr_scheduling_gamma is not None:\n",
    "        scheduler = lr_scheduler.ExponentialLR(\n",
    "            optimizer, gamma=lr_scheduling_gamma)\n",
    "\n",
    "    # Writer for Tensorboard\n",
    "    if write_logs:\n",
    "        writer = SummaryWriter(output_dir)\n",
    "\n",
    "    # Train the model\n",
    "    best_loss = 0\n",
    "    step = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch: {epoch}\")\n",
    "\n",
    "        # Curriculum defines the order of the training\n",
    "        for current_dataset_id in curriculum:\n",
    "\n",
    "            _train_dir = os.path.join(train_dir, current_dataset_id)\n",
    "            print(f\"Training on dataset: {_train_dir}\")\n",
    "\n",
    "            # Training dataset\n",
    "            train_dataset = PatchDataset(\n",
    "                # Directory containing the dataset\n",
    "                _train_dir,\n",
    "                # Expected slices per fragment\n",
    "                slice_depth=slice_depth,\n",
    "                # Size of an individual patch\n",
    "                patch_size_x=patch_size_x,\n",
    "                patch_size_y=patch_size_y,\n",
    "                # Image resize ratio\n",
    "                resize_ratio=resize_ratio,\n",
    "                # Training vs Testing mode\n",
    "                train=True,\n",
    "            )\n",
    "            total_dataset_size = len(train_dataset)\n",
    "            print(f\"Raw train dataset size: {total_dataset_size}\")\n",
    "\n",
    "            # Add augmentations\n",
    "            img_transform_list = [\n",
    "                transforms.Normalize(train_dataset.mean, train_dataset.std)\n",
    "            ]\n",
    "            if image_augs:\n",
    "                img_transform_list += [\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.RandomVerticalFlip(),\n",
    "                ]\n",
    "            img_transform = transforms.Compose(img_transform_list)\n",
    "\n",
    "            # DataLoaders\n",
    "            train_dataloader = DataLoader(\n",
    "                train_dataset,\n",
    "                batch_size=batch_size,\n",
    "                sampler=RandomSampler(\n",
    "                    train_dataset, num_samples=max_samples_per_dataset),\n",
    "                num_workers=num_workers,\n",
    "                # This will make it go faster if it is loaded into a GPU\n",
    "                pin_memory=True,\n",
    "            )\n",
    "\n",
    "            print(f\"Training...\")\n",
    "            train_loss = 0\n",
    "            for patch, label in tqdm(train_dataloader):\n",
    "                optimizer.zero_grad()\n",
    "                # writer.add_histogram('patch_input', patch, step)\n",
    "                # writer.add_histogram('label_input', label, step)\n",
    "                patch = patch.to(device)\n",
    "                patch = img_transform(patch)\n",
    "                pred = model(patch)\n",
    "                label = label.to(device)\n",
    "                loss = loss_fn(pred, label)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                step += 1\n",
    "                train_loss += loss.item()\n",
    "\n",
    "                # Check if we have exceeded the time limit\n",
    "                time_elapsed = time.time() - time_start\n",
    "                if time_elapsed > time_train_max_seconds:\n",
    "                    print(\"Time limit exceeded, stopping batches\")\n",
    "                    break\n",
    "\n",
    "            train_loss /= max_samples_per_dataset\n",
    "            if write_logs:\n",
    "                writer.add_scalar(\n",
    "                    f'{loss_fn.__class__.__name__}/{current_dataset_id}/train', train_loss, step)\n",
    "\n",
    "            if save_model and train_loss < best_loss:\n",
    "                best_loss = train_loss\n",
    "                torch.save(model.state_dict(), f\"{output_dir}/model.pth\")\n",
    "\n",
    "            # Check if we have exceeded the time limit\n",
    "            time_elapsed = time.time() - time_start\n",
    "            if time_elapsed > time_train_max_seconds:\n",
    "                print(\"Time limit exceeded, stopping curriculum\")\n",
    "                break\n",
    "\n",
    "        if lr_scheduling_gamma is not None:\n",
    "            before_lr = optimizer.param_groups[0][\"lr\"]\n",
    "            scheduler.step()\n",
    "            after_lr = optimizer.param_groups[0][\"lr\"]\n",
    "            print(\"Epoch %d: SGD lr %.4f -> %.4f\" %\n",
    "                  (epoch, before_lr, after_lr))\n",
    "\n",
    "        # Check if we have exceeded the time limit\n",
    "        time_elapsed = time.time() - time_start\n",
    "        if time_elapsed > time_train_max_seconds:\n",
    "            print(\"Time limit exceeded, stopping training\")\n",
    "            break\n",
    "\n",
    "    if write_logs:\n",
    "        writer.close()  # Close the SummaryWriter\n",
    "\n",
    "    del train_dataloader, train_dataset\n",
    "    clear_gpu_memory()\n",
    "    model.eval()\n",
    "\n",
    "    if save_submit_csv:\n",
    "        submission_filepath = os.path.join(output_dir, 'submission.csv')\n",
    "        with open(submission_filepath, 'w') as f:\n",
    "            # Write header\n",
    "            f.write(\"Id,Predicted\\n\")\n",
    "\n",
    "    # Baseline is to use image mask to create guess submission\n",
    "    for subtest_name in os.listdir(eval_dir):\n",
    "\n",
    "        # Name of sub-directory inside test dir\n",
    "        subtest_filepath = os.path.join(eval_dir, subtest_name)\n",
    "\n",
    "        # Evaluation dataset\n",
    "        eval_dataset = PatchDataset(\n",
    "            # Directory containing the dataset\n",
    "            subtest_filepath,\n",
    "            # Expected slices per fragment\n",
    "            slice_depth=slice_depth,\n",
    "            # Size of an individual patch\n",
    "            patch_size_x=patch_size_x,\n",
    "            patch_size_y=patch_size_y,\n",
    "            # Image resize ratio\n",
    "            resize_ratio=resize_ratio,\n",
    "            # Training vs Testing mode\n",
    "            train=False,\n",
    "        )\n",
    "\n",
    "        # DataLoaders\n",
    "        eval_dataloader = DataLoader(\n",
    "            eval_dataset,\n",
    "            batch_size=batch_size,\n",
    "            sampler=SequentialSampler(eval_dataset),\n",
    "            num_workers=num_workers,\n",
    "            # This will make it go faster if it is loaded into a GPU\n",
    "            pin_memory=True,\n",
    "        )\n",
    "        img_transform = transforms.Compose([\n",
    "            transforms.Normalize(eval_dataset.mean, eval_dataset.std)\n",
    "        ])\n",
    "\n",
    "        # Make a blank prediction image\n",
    "        pred_image = np.zeros(eval_dataset.resized_size, dtype=np.float32).T\n",
    "        print(f\"Prediction image {subtest_name} shape: {pred_image.shape}\")\n",
    "        print(f\"Prediction image min: {pred_image.min()}, max: {pred_image.max()}\")\n",
    "\n",
    "        for i, batch in enumerate(tqdm(eval_dataloader)):\n",
    "            batch = batch.to(device)\n",
    "            batch = img_transform(batch)\n",
    "            with torch.no_grad():\n",
    "                preds = model(batch)\n",
    "                preds = torch.sigmoid(preds)\n",
    "\n",
    "            # Iterate through each image and prediction in the batch\n",
    "            for j, pred in enumerate(preds):\n",
    "                pixel_index = eval_dataset.mask_indices[i * batch_size + j]\n",
    "                pred_image[pixel_index[0], pixel_index[1]] = pred\n",
    "\n",
    "        if write_logs:\n",
    "            print(\"Writing prediction image to TensorBoard...\")\n",
    "            # Add batch dimmension to pred_image for Tensorboard\n",
    "            writer.add_image(f'pred_{subtest_name}', np.expand_dims(pred_image, axis=0), step)\n",
    "\n",
    "        # Resize pred_image to original size\n",
    "        img = Image.fromarray(pred_image * 255).convert('1')\n",
    "        img = img.resize((\n",
    "            eval_dataset.original_size[0],\n",
    "            eval_dataset.original_size[1],\n",
    "        ), resample=Image.BILINEAR)\n",
    "\n",
    "        if save_pred_img:\n",
    "            print(\"Saving prediction image...\")\n",
    "            _image_filepath = os.path.join(output_dir, f\"pred_{subtest_name}.png\")\n",
    "            img.save(_image_filepath)\n",
    "\n",
    "        if postprocess:\n",
    "            print(\"Postprocessing...\")\n",
    "            # Erosion then Dilation \n",
    "            _filter_size = 3\n",
    "            img = img.filter(ImageFilter.MinFilter(_filter_size))\n",
    "            img = img.filter(ImageFilter.MaxFilter(_filter_size))\n",
    "\n",
    "        if save_pred_img:\n",
    "            print(\"Saving prediction image...\")\n",
    "            _image_filepath = os.path.join(output_dir, f\"pred_{subtest_name}_post.png\")\n",
    "            img.save(_image_filepath)\n",
    "\n",
    "        if save_submit_csv:\n",
    "            print(\"Saving submission csv...\")\n",
    "            starts_ix, lengths = image_to_rle(np.array(img), threshold=threshold)\n",
    "            inklabels_rle = \" \".join(map(str, sum(zip(starts_ix, lengths), ())))\n",
    "            with open(submission_filepath, 'a') as f:\n",
    "                f.write(f\"{subtest_name},{inklabels_rle}\\n\")\n",
    "\n",
    "    if save_pred_img and save_submit_csv:\n",
    "        save_rle_as_image(submission_filepath, output_dir, pred_image.shape)\n",
    "\n",
    "    return best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import os\n",
    "\n",
    "import pprint\n",
    "import numpy as np\n",
    "from hyperopt import fmin, hp, tpe\n",
    "\n",
    "def objective(hparams) -> float:\n",
    "\n",
    "    # Print hyperparam dict with logging\n",
    "    print(f\"\\n\\nHyperparams:\\n\\n{pprint.pformat(hparams)}\\n\\n\")\n",
    "\n",
    "    # Add UUID to run name for ultimate uniqueness\n",
    "    run_name: str = str(uuid.uuid4())[:8] + '_'\n",
    "    for key, value in hparams.items():\n",
    "        # Choose name of run based on hparams\n",
    "        if key in [\n",
    "            'model',\n",
    "            'freeze_backbone',\n",
    "            'use_gelu',\n",
    "            'curriculum',\n",
    "            'optimizer',\n",
    "            'lr_scheduling_gamma',\n",
    "            'image_augs',\n",
    "            # 'patch_size_x',\n",
    "            # 'patch_size_y',\n",
    "            'resize_ratio',\n",
    "            # 'num_epochs',\n",
    "            # 'batch_size',\n",
    "            'lr',\n",
    "            'max_samples_per_dataset',\n",
    "        ]:\n",
    "            run_name += f'{key}_{str(value)}_'\n",
    "\n",
    "    # Create directory based on run_name\n",
    "    output_dir = os.path.join(hparams['output_dir'], run_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Save hyperparams to file\n",
    "    with open(os.path.join(output_dir, 'hparams.txt'), 'w') as f:\n",
    "        f.write(pprint.pformat(hparams))\n",
    "    \n",
    "    try:\n",
    "        # Train and evaluate a TFLite model\n",
    "        loss: float = train_loop(\n",
    "            # Directories and datasets\n",
    "            output_dir=output_dir,\n",
    "            train_dir=hparams['train_dir'],\n",
    "            eval_dir=hparams['eval_dir'],\n",
    "            curriculum=hparams['curriculum'],\n",
    "            image_augs=hparams['image_augs'],\n",
    "            resize_ratio=hparams['resize_ratio'],\n",
    "            num_workers=hparams['num_workers'],\n",
    "            max_samples_per_dataset=hparams['max_samples_per_dataset'],\n",
    "            # Model and training\n",
    "            model=hparams['model'],\n",
    "            freeze_backbone=hparams['freeze_backbone'],\n",
    "            optimizer=hparams['optimizer'],\n",
    "            lr_scheduling_gamma=hparams['lr_scheduling_gamma'],\n",
    "            use_gelu=hparams['use_gelu'],\n",
    "            slice_depth=hparams['slice_depth'],\n",
    "            patch_size_x=hparams['patch_size_x'],\n",
    "            patch_size_y=hparams['patch_size_y'],\n",
    "            batch_size=hparams['batch_size'],\n",
    "            lr=hparams['lr'],\n",
    "            num_epochs=hparams['num_epochs'],\n",
    "            save_pred_img=True,\n",
    "            save_submit_csv=False,\n",
    "            write_logs = True,\n",
    "            save_model=True,\n",
    "            max_time_hours = 8,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"\\n\\n Model Training FAILED with \\n{e}\\n\\n\")\n",
    "        loss = 10000.0\n",
    "    return loss\n",
    "\n",
    "# Define the search space\n",
    "search_space = {\n",
    "    'train_dir' : \"C:\\\\Users\\\\ook\\\\Documents\\\\dev\\\\ashenvenus\\\\data\\\\train\",\n",
    "    'eval_dir' : \"C:\\\\Users\\\\ook\\\\Documents\\\\dev\\\\ashenvenus\\\\data\\\\test\",\n",
    "    'output_dir' : \"C:\\\\Users\\\\ook\\\\Documents\\\\dev\\\\ashenvenus\\\\output\",\n",
    "    'curriculum': hp.choice('curriculum', [\n",
    "        # '1',\n",
    "        # '2',\n",
    "        # '3',\n",
    "        '123',\n",
    "        '321',\n",
    "        '13',\n",
    "        '32',\n",
    "    ]),\n",
    "    'model': hp.choice('model', [\n",
    "        'simplenet',\n",
    "        'convnext_tiny', # Good\n",
    "        # 'swin_t',\n",
    "        'resnext50_32x4d', # Potentially also good\n",
    "        # 'vit_b_32',\n",
    "    ]),\n",
    "    'freeze_backbone': hp.choice('freeze_backbone', [\n",
    "        True,\n",
    "        False,\n",
    "    ]),\n",
    "    'use_gelu' : hp.choice('use_gelu', [\n",
    "        True,\n",
    "        False,\n",
    "    ]),\n",
    "    'image_augs': hp.choice('image_augs', [\n",
    "        True,\n",
    "        False,\n",
    "    ]),\n",
    "    'optimizer': hp.choice('optimizer', [\n",
    "        'adam',\n",
    "        # 'sgd', # Garbo\n",
    "    ]),\n",
    "    'lr_scheduling_gamma': hp.choice('lr_scheduling_gamma', [\n",
    "        # 0.1, # Garbo\n",
    "        0.9,\n",
    "        0.98,\n",
    "        None,\n",
    "    ]),\n",
    "    'slice_depth': 65,\n",
    "    'num_workers': 0,\n",
    "    'batch_size': hp.choice('batch_size', [1028]),\n",
    "    'lr': hp.loguniform('lr',  np.log(0.00000001), np.log(0.001)),\n",
    "    'num_epochs': hp.choice('num_epochs', [8, 16, 32]),\n",
    "    'patch_size_x': hp.choice('patch_size_x', [64]),\n",
    "    'patch_size_y': hp.choice('patch_size_y', [64]),\n",
    "    'resize_ratio': hp.choice('resize_ratio', [0.08]),\n",
    "    'max_samples_per_dataset': hp.choice('max_samples_per_dataset', [120000, 60000]),\n",
    "}\n",
    "\n",
    "# Run the optimization\n",
    "best = fmin(\n",
    "    objective,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=100,\n",
    "    rstate=np.random.default_rng(),\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ashenvenus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
