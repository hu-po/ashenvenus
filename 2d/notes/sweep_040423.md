Copy over files from linux computers to windows computer:

```
scp -r tren@192.168.1.30:/home/tren/dev/ashenvenus/output/* C:\Users\ook\Documents\dev\ashenvenus\output\
scp -r oop@192.168.1.34:/home/oop/dev/ashenvenus/output/* C:\Users\ook\Documents\dev\ashenvenus\output\
```

Great runs

(c39ac15b|82934db2|7a7a91cf|29d55a5f|77b1f3dc)

Okay runs

(49cee3f6|e40f6408|97e70391|73885935)

Learnings

- `num_samples` - 120k is better than 60k which is better than 8k. The question here is how big can you get before blowing up memory. Bigger is always better.
- `model` - Bigger model is better, resnext50_32x4d actually does better then convnext_small
- `freeze` - Not freezing actually works better but I think its because its overfitting to the train data and since the test data is the train data it works better.
- `num_epochs` and `max_time_hours` longer are better obviously.
- `relu` does consistently better than `gelu`, but high scores exist with both
- `321` works better than `123` probably due to catastrophic forgetting and testing on train.