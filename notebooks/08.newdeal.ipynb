{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import subprocess\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import (\n",
    "    convnext_tiny, ConvNeXt_Tiny_Weights,\n",
    "    vit_b_32, ViT_B_32_Weights,\n",
    "    resnext50_32x4d, ResNeXt50_32X4D_Weights,\n",
    "    swin_t, Swin_T_Weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        # Directory containing the datasets\n",
    "        data_dir: str,\n",
    "        # Expected slices per fragment\n",
    "        slice_depth: int = 4,\n",
    "        # Size of an individual patch\n",
    "        patch_size_x: int = 1028,\n",
    "        patch_size_y: int = 256,\n",
    "        # Image resize ratio\n",
    "        resize_ratio: float = 1.0,\n",
    "        # Training vs Testing mode\n",
    "        train: bool = True,\n",
    "        # Filenames of the images we'll use\n",
    "        image_mask_filename='mask.png',\n",
    "        image_labels_filename='inklabels.png',\n",
    "        slices_dir_filename='surface_volume',\n",
    "    ):\n",
    "        print(f\"Initializing CurriculumDataset\")\n",
    "        # Train mode also loads the labels\n",
    "        self.train = train\n",
    "        # Resize ratio reduces the size of the image\n",
    "        self.resize_ratio = resize_ratio\n",
    "        # Data will be B x slice_depth x patch_size_x x patch_size_y\n",
    "        self.patch_size_x = patch_size_x\n",
    "        self.patch_size_y = patch_size_y\n",
    "        self.patch_size_x_half = int(patch_size_x / 2)\n",
    "        self.patch_size_y_half = int(patch_size_y / 2)\n",
    "        self.slice_depth = slice_depth\n",
    "        assert os.path.exists(\n",
    "            data_dir), f\"Data directory {data_dir} does not exist\"\n",
    "        # Open Mask image\n",
    "        _image_mask_filepath = os.path.join(data_dir, image_mask_filename)\n",
    "        _mask_img = Image.open(_image_mask_filepath).convert(\"1\")\n",
    "        # Get original size and resized size\n",
    "        self.original_size = _mask_img.size\n",
    "        self.resized_size = (\n",
    "            int(self.original_size[0] * self.resize_ratio),\n",
    "            int(self.original_size[1] * self.resize_ratio),\n",
    "        )\n",
    "        # Resize the mask\n",
    "        # print(f\"Mask original size: {original_size}\")\n",
    "        _mask_img = _mask_img.resize(self.resized_size, resample=Image.BILINEAR)\n",
    "        # print(f\"Mask resized size: {_mask_img.size}\")\n",
    "        _mask = torch.from_numpy(np.array(_mask_img)).to(torch.bool)\n",
    "        # print(f\"Mask tensor shape: {_mask.shape}\")\n",
    "        # print(f\"Mask tensor dtype: {_mask.dtype}\")\n",
    "        if train:\n",
    "            _image_labels_filepath = os.path.join(\n",
    "                data_dir, image_labels_filename)\n",
    "            _labels_img = Image.open(_image_labels_filepath).convert(\"1\")\n",
    "            # print(f\"Labels original size: {original_size}\")\n",
    "            _labels_img = _labels_img.resize(\n",
    "                self.resized_size, resample=Image.BILINEAR)\n",
    "            # print(f\"Labels resized size: {_labels_img.size}\")\n",
    "            self.labels = torch.from_numpy(\n",
    "                np.array(_labels_img)).to(torch.bool)\n",
    "            # print(f\"Labels tensor shape: {self.labels.shape}\")\n",
    "            # print(f\"Labels tensor dtype: {self.labels.dtype}\")\n",
    "        # Pre-allocate the entire fragment\n",
    "        self.fragment = torch.zeros((\n",
    "            self.slice_depth,\n",
    "            self.resized_size[1],\n",
    "            self.resized_size[0],\n",
    "        ), dtype=torch.float32\n",
    "        )\n",
    "        # print(f\"Fragment tensor shape: {self.fragment.shape}\")\n",
    "        # print(f\"Fragment tensor dtype: {self.fragment.dtype}\")\n",
    "        # Open up slices\n",
    "        _slice_dir = os.path.join(data_dir, slices_dir_filename)\n",
    "        for i in tqdm(range(self.slice_depth)):\n",
    "            _slice_filepath = os.path.join(_slice_dir, f\"{i:02d}.tif\")\n",
    "            _slice_img = Image.open(_slice_filepath).convert('F')\n",
    "            # print(f\"Slice original size: {original_size}\")\n",
    "            _slice_img = _slice_img.resize(\n",
    "                self.resized_size, resample=Image.BILINEAR)\n",
    "            # print(f\"Slice resized size: {_slice_img.size}\")\n",
    "            _slice = torch.from_numpy(np.array(_slice_img)/65535.0)\n",
    "            # print(f\"Slice tensor shape: {_slice.shape}\")\n",
    "            # print(f\"Slice tensor dtype: {_slice.dtype}\")\n",
    "            self.fragment[i, :, :] = _slice\n",
    "\n",
    "        print(f\"Fragment tensor shape: {self.fragment.shape}\")\n",
    "        print(f\"Fragment tensor dtype: {self.fragment.dtype}\")\n",
    "        print(f\"Fragment tensor min: {self.fragment.min()}\")\n",
    "        print(f\"Fragment tensor max: {self.fragment.max()}\")\n",
    "        # print(f\"Fragment tensor mean: {self.fragment.mean()}\")\n",
    "        # print(f\"Fragment tensor std: {self.fragment.std()}\")\n",
    "\n",
    "        # Get mean/std for fragment only on mask indices\n",
    "        _fragment_mask = _mask.unsqueeze(0).expand(self.slice_depth, -1, -1)\n",
    "        self.mean = self.fragment[_fragment_mask].mean()\n",
    "        self.std = self.fragment[_fragment_mask].std()\n",
    "        # print(f\"Fragment tensor mean (no mask): {self.mean}\")\n",
    "        # print(f\"Fragment tensor std (no mask): {self.std}\")\n",
    "\n",
    "        # Get indices where mask is 1\n",
    "        self.mask_indices = torch.nonzero(_mask).to(torch.int32)\n",
    "        # print(f\"Mask indices shape: {self.mask_indices.shape}\")\n",
    "        # print(f\"Mask indices dtype: {self.mask_indices.dtype}\")\n",
    "\n",
    "        # Pad the fragment with zeros based on patch size\n",
    "        self.fragment = F.pad(\n",
    "            self.fragment,\n",
    "            (\n",
    "                # Padding in Y\n",
    "                self.patch_size_y_half, self.patch_size_y_half,\n",
    "                # Padding in X\n",
    "                self.patch_size_x_half, self.patch_size_x_half,\n",
    "                # No padding on z\n",
    "                0, 0,\n",
    "            ),\n",
    "            mode='constant',\n",
    "            value=0,\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.mask_indices.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        # Get the x, y from the mask indices\n",
    "        x, y = self.mask_indices[index]\n",
    "        # print(f\"Index: {index}, x: {x}, y: {y}\")\n",
    "\n",
    "        # Pre-allocate the patch\n",
    "        patch = self.fragment[\n",
    "                :,\n",
    "                x: x + self.patch_size_x,\n",
    "                y: y + self.patch_size_y,\n",
    "        ]\n",
    "        # print(f\"Patch tensor shape: {patch.shape}\")\n",
    "        # print(f\"Patch tensor dtype: {patch.dtype}\")\n",
    "        # print(f\"Patch tensor min: {patch.min()}\")\n",
    "        # print(f\"Patch tensor max: {patch.max()}\")\n",
    "\n",
    "        # Label is going to be the label of the center voxel\n",
    "        if self.train:\n",
    "            label = self.labels[\n",
    "                x,\n",
    "                y,\n",
    "            ]\n",
    "            return patch, label.unsqueeze(0).to(torch.float32)\n",
    "        else:\n",
    "            # If we're not training, we don't have labels\n",
    "            return patch\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Using GPU\")\n",
    "        return torch.device(\"cuda\")\n",
    "    else:\n",
    "        print(\"Using CPU\")\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "def rle(img, threshold=0.5):\n",
    "    # TODO: Histogram of image to see where threshold should be\n",
    "    flat_img = img.flatten()\n",
    "    flat_img = np.where(flat_img > threshold, 1, 0).astype(np.uint8)\n",
    "    starts = np.array((flat_img[:-1] == 0) & (flat_img[1:] == 1))\n",
    "    ends = np.array((flat_img[:-1] == 1) & (flat_img[1:] == 0))\n",
    "    starts_ix = np.where(starts)[0] + 2\n",
    "    ends_ix = np.where(ends)[0] + 2\n",
    "    lengths = ends_ix - starts_ix\n",
    "    return starts_ix, lengths\n",
    "\n",
    "\n",
    "def get_gpu_memory():\n",
    "    result = subprocess.run(['nvidia-smi', '--query-gpu=memory.used,memory.free',\n",
    "                             '--format=csv,nounits,noheader'], stdout=subprocess.PIPE, text=True)\n",
    "    gpu_memory = [tuple(map(int, line.split(',')))\n",
    "                  for line in result.stdout.strip().split('\\n')]\n",
    "    for i, (used, free) in enumerate(gpu_memory):\n",
    "        print(f\"GPU {i}: Memory Used: {used} MiB | Memory Available: {free} MiB\")\n",
    "\n",
    "\n",
    "def clear_gpu_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        print('Clearing GPU memory')\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "class PreTrainNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        slice_depth: int = 65,\n",
    "        pretrained_model: str = 'convnext_tiny',\n",
    "        freeze_backbone: bool = False,\n",
    "        pretrained_weights_filepath: str = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(slice_depth, 3, 3)\n",
    "        # Load pretrained model\n",
    "        if pretrained_model == 'convnext_tiny':\n",
    "            if pretrained_weights_filepath is not None:\n",
    "                self.pre_trained_model = convnext_tiny()\n",
    "            else:\n",
    "                _weights = ConvNeXt_Tiny_Weights.DEFAULT\n",
    "                self.pre_trained_model = convnext_tiny(weights=_weights)\n",
    "        elif pretrained_model == 'vit_b_32':\n",
    "            if pretrained_weights_filepath is not None:\n",
    "                self.pre_trained_model = vit_b_32()\n",
    "            else:\n",
    "                _weights = ViT_B_32_Weights.DEFAULT\n",
    "                self.pre_trained_model = vit_b_32(weights=_weights)\n",
    "        elif pretrained_model == 'swin_t':\n",
    "            if pretrained_weights_filepath is not None:\n",
    "                self.pre_trained_model = swin_t()\n",
    "            else:\n",
    "                _weights = Swin_T_Weights.DEFAULT\n",
    "                self.pre_trained_model = swin_t(weights=_weights)\n",
    "        elif pretrained_model == 'resnext50_32x4d':\n",
    "            if pretrained_weights_filepath is not None:\n",
    "                self.pre_trained_model = resnext50_32x4d()\n",
    "            else:\n",
    "                _weights = ResNeXt50_32X4D_Weights.DEFAULT\n",
    "                self.pre_trained_model = resnext50_32x4d(weights=_weights)\n",
    "        if pretrained_weights_filepath is not None:\n",
    "            self.model.load_state_dict(pretrained_weights_filepath)\n",
    "        # Put model in training mode\n",
    "        if freeze_backbone:\n",
    "            self.pre_trained_model.eval()\n",
    "        else:\n",
    "            self.pre_trained_model.train()\n",
    "        # Binary classification head on top\n",
    "        self.fc = nn.LazyLinear(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.pre_trained_model(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        slice_depth: int = 65,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(slice_depth, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.LazyLinear(120)\n",
    "        self.fc2 = nn.LazyLinear(84)\n",
    "        self.fc3 = nn.LazyLinear(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def train_loop(\n",
    "    train_dir: str = \"data/train/\",\n",
    "    eval_dir: str = \"data/eval/\",\n",
    "    model: str = \"simplenet\",\n",
    "    freeze_backbone: bool = False,\n",
    "    pretrained_weights_filepath: str = None,\n",
    "    optimizer: str = \"adam\",\n",
    "    curriculum: str = \"1\",\n",
    "    max_samples_per_dataset: int = 100,\n",
    "    output_dir: str = \"output/train\",\n",
    "    image_augs: bool = False,\n",
    "    slice_depth: int = 3,\n",
    "    patch_size_x: int = 512,\n",
    "    patch_size_y: int = 128,\n",
    "    resize_ratio: float = 1.0,\n",
    "    batch_size: int = 16,\n",
    "    lr: float = 0.001,\n",
    "    lr_scheduling_gamma: float = None,\n",
    "    num_epochs: int = 2,\n",
    "    num_workers: int = 1,\n",
    "    write_logs: bool = False,\n",
    "    save_pred_img: bool = False,\n",
    "    save_submit_csv: bool = False,\n",
    "    threshold: float = 0.5,\n",
    "    max_time_hours: float = 8,\n",
    "):\n",
    "    device = get_device()\n",
    "    clear_gpu_memory()\n",
    "\n",
    "    # Notebook will only run for this amount of time\n",
    "    time_train_max_seconds = max_time_hours * 60 * 60\n",
    "    time_start = time.time()\n",
    "    time_elapsed = 0\n",
    "\n",
    "    # Load the model, try to fit on GPU\n",
    "    if model == \"simplenet\":\n",
    "        model = SimpleNet(\n",
    "            slice_depth=slice_depth,\n",
    "        )\n",
    "    elif model == 'convnext_tiny':\n",
    "        model = PreTrainNet(\n",
    "            slice_depth=slice_depth,\n",
    "            pretrained_model='convnext_tiny',\n",
    "            freeze_backbone=freeze_backbone,\n",
    "            pretrained_weights_filepath=pretrained_weights_filepath,\n",
    "        )\n",
    "    elif model == 'vit_b_32':\n",
    "        model = PreTrainNet(\n",
    "            slice_depth=slice_depth,\n",
    "            pretrained_model='vit_b_32',\n",
    "            freeze_backbone=freeze_backbone,\n",
    "            pretrained_weights_filepath=pretrained_weights_filepath,\n",
    "        )\n",
    "    elif model == 'swin_t':\n",
    "        model = PreTrainNet(\n",
    "            slice_depth=slice_depth,\n",
    "            pretrained_model='swin_t',\n",
    "            freeze_backbone=freeze_backbone,\n",
    "            pretrained_weights_filepath=pretrained_weights_filepath,\n",
    "        )\n",
    "    elif model == 'resnext50_32x4d':\n",
    "        model = PreTrainNet(\n",
    "            slice_depth=slice_depth,\n",
    "            pretrained_model='resnext50_32x4d',\n",
    "            freeze_backbone=freeze_backbone,\n",
    "            pretrained_weights_filepath=pretrained_weights_filepath,\n",
    "        )\n",
    "    elif model == \"simplenet_norm\":\n",
    "        model = SimpleNetNorm(\n",
    "            slice_depth=slice_depth,\n",
    "        )\n",
    "    model = model.to(device)\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Create optimizers\n",
    "    if optimizer == \"adam\":\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    elif optimizer == \"sgd\":\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    if lr_scheduling_gamma is not None:\n",
    "        scheduler = lr_scheduler.ExponentialLR(\n",
    "            optimizer, gamma=lr_scheduling_gamma)\n",
    "\n",
    "    # Writer for Tensorboard\n",
    "    if write_logs:\n",
    "        writer = SummaryWriter(output_dir)\n",
    "\n",
    "    # Train the model\n",
    "    best_loss = 0\n",
    "    step = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch: {epoch}\")\n",
    "\n",
    "        # Curriculum defines the order of the training\n",
    "        for current_dataset_id in curriculum:\n",
    "\n",
    "            _train_dir = os.path.join(train_dir, current_dataset_id)\n",
    "            print(f\"Training on dataset: {_train_dir}\")\n",
    "\n",
    "            # Training dataset\n",
    "            train_dataset = PatchDataset(\n",
    "                # Directory containing the dataset\n",
    "                _train_dir,\n",
    "                # Expected slices per fragment\n",
    "                slice_depth=slice_depth,\n",
    "                # Size of an individual patch\n",
    "                patch_size_x=patch_size_x,\n",
    "                patch_size_y=patch_size_y,\n",
    "                # Image resize ratio\n",
    "                resize_ratio=resize_ratio,\n",
    "                # Training vs Testing mode\n",
    "                train=True,\n",
    "            )\n",
    "            total_dataset_size = len(train_dataset)\n",
    "            print(f\"Raw train dataset size: {total_dataset_size}\")\n",
    "\n",
    "            # Add augmentations\n",
    "            img_transform_list = [\n",
    "                transforms.Normalize(train_dataset.mean, train_dataset.std)\n",
    "            ]\n",
    "            if image_augs:\n",
    "                img_transform_list += [\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.RandomVerticalFlip(),\n",
    "                ]\n",
    "            img_transform = transforms.Compose(img_transform_list)\n",
    "\n",
    "            # DataLoaders\n",
    "            train_dataloader = DataLoader(\n",
    "                train_dataset,\n",
    "                batch_size=batch_size,\n",
    "                sampler=RandomSampler(\n",
    "                    train_dataset, num_samples=max_samples_per_dataset),\n",
    "                num_workers=num_workers,\n",
    "                # This will make it go faster if it is loaded into a GPU\n",
    "                pin_memory=True,\n",
    "            )\n",
    "\n",
    "            print(f\"Training...\")\n",
    "            train_loss = 0\n",
    "            for patch, label in tqdm(train_dataloader):\n",
    "                optimizer.zero_grad()\n",
    "                # writer.add_histogram('patch_input', patch, step)\n",
    "                # writer.add_histogram('label_input', label, step)\n",
    "                patch = patch.to(device)\n",
    "                patch = img_transform(patch)\n",
    "                pred = model(patch)\n",
    "                label = label.to(device)\n",
    "                loss = loss_fn(pred, label)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                step += 1\n",
    "                train_loss += loss.item()\n",
    "\n",
    "                # Check if we have exceeded the time limit\n",
    "                time_elapsed = time.time() - time_start\n",
    "                if time_elapsed > time_train_max_seconds:\n",
    "                    print(\"Time limit exceeded, stopping batches\")\n",
    "                    break\n",
    "\n",
    "            train_loss /= max_samples_per_dataset\n",
    "            if write_logs:\n",
    "                writer.add_scalar(\n",
    "                    f'{loss_fn.__class__.__name__}/{current_dataset_id}/train', train_loss, step)\n",
    "\n",
    "            if train_loss < best_loss:\n",
    "                best_loss = train_loss\n",
    "                # torch.save(model.state_dict(), f\"{output_dir}/model.pth\")\n",
    "\n",
    "            # Check if we have exceeded the time limit\n",
    "            time_elapsed = time.time() - time_start\n",
    "            if time_elapsed > time_train_max_seconds:\n",
    "                print(\"Time limit exceeded, stopping curriculum\")\n",
    "                break\n",
    "\n",
    "        if lr_scheduling_gamma is not None:\n",
    "            before_lr = optimizer.param_groups[0][\"lr\"]\n",
    "            scheduler.step()\n",
    "            after_lr = optimizer.param_groups[0][\"lr\"]\n",
    "            print(\"Epoch %d: SGD lr %.4f -> %.4f\" %\n",
    "                  (epoch, before_lr, after_lr))\n",
    "\n",
    "        # Check if we have exceeded the time limit\n",
    "        time_elapsed = time.time() - time_start\n",
    "        if time_elapsed > time_train_max_seconds:\n",
    "            print(\"Time limit exceeded, stopping training\")\n",
    "            break\n",
    "\n",
    "    if write_logs:\n",
    "        writer.close()  # Close the SummaryWriter\n",
    "\n",
    "    del train_dataloader, train_dataset\n",
    "    clear_gpu_memory()\n",
    "\n",
    "    if save_submit_csv:\n",
    "        # Create submission file\n",
    "        submission_filepath = 'submission.csv'\n",
    "        with open(submission_filepath, 'w') as f:\n",
    "            # Write header\n",
    "            f.write(\"Id,Predicted\\n\")\n",
    "\n",
    "    # Baseline is to use image mask to create guess submission\n",
    "    for subtest_name in os.listdir(eval_dir):\n",
    "\n",
    "        # Name of sub-directory inside test dir\n",
    "        subtest_filepath = os.path.join(eval_dir, subtest_name)\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        # Evaluation dataset\n",
    "        eval_dataset = PatchDataset(\n",
    "            # Directory containing the dataset\n",
    "            subtest_filepath,\n",
    "            # Expected slices per fragment\n",
    "            slice_depth=slice_depth,\n",
    "            # Size of an individual patch\n",
    "            patch_size_x=patch_size_x,\n",
    "            patch_size_y=patch_size_y,\n",
    "            # Image resize ratio\n",
    "            resize_ratio=resize_ratio,\n",
    "            # Training vs Testing mode\n",
    "            train=False,\n",
    "        )\n",
    "\n",
    "        # DataLoaders\n",
    "        eval_dataloader = DataLoader(\n",
    "            eval_dataset,\n",
    "            batch_size=batch_size,\n",
    "            sampler=SequentialSampler(eval_dataset),\n",
    "            num_workers=num_workers,\n",
    "            # This will make it go faster if it is loaded into a GPU\n",
    "            pin_memory=True,\n",
    "        )\n",
    "        img_transform = transforms.Compose([\n",
    "            transforms.Normalize(eval_dataset.mean, eval_dataset.std)\n",
    "        ])\n",
    "\n",
    "        # Make a blank prediction image\n",
    "        pred_image = np.zeros(eval_dataset.resized_size, dtype=np.uint8).T\n",
    "        print(f\"Prediction image {subtest_name} shape: {pred_image.shape}\")\n",
    "\n",
    "        for i, batch in enumerate(tqdm(eval_dataloader)):\n",
    "            batch = batch.to(device)\n",
    "            batch = img_transform(batch)\n",
    "            with torch.no_grad():\n",
    "                preds = model(batch)\n",
    "                preds = torch.sigmoid(preds)\n",
    "\n",
    "            # Iterate through each image and prediction in the batch\n",
    "            for j, pred in enumerate(preds):\n",
    "                pixel_index = eval_dataset.mask_indices[i * batch_size + j]\n",
    "                pred_image[pixel_index[0], pixel_index[1]] = pred\n",
    "\n",
    "                if pred > threshold:\n",
    "                    pred_image[pixel_index[0], pixel_index[1]] = 1\n",
    "\n",
    "        if save_pred_img:\n",
    "            # Save the prediction image\n",
    "            _img = Image.fromarray(pred_image * 255)\n",
    "            _img.save(f\"{output_dir}/pred_image_{subtest_name}.png\")\n",
    "\n",
    "        if save_submit_csv:\n",
    "            # Resize pred_image to original size\n",
    "            _img = Image.fromarray(pred_image)\n",
    "            _img = _img.resize((\n",
    "                eval_dataset.original_size[0],\n",
    "                eval_dataset.original_size[1],\n",
    "            ))\n",
    "            pred_image = np.array(_img)\n",
    "\n",
    "            starts_ix, lengths = rle(pred_image)\n",
    "            inklabels_rle = \" \".join(map(str, sum(zip(starts_ix, lengths), ())))\n",
    "            with open(submission_filepath, 'a') as f:\n",
    "                f.write(f\"{subtest_name},{inklabels_rle}\\n\")\n",
    "\n",
    "    return best_loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loop(\n",
    "    # # Submission\n",
    "    # train_dir = '/kaggle/input/vesuvius-challenge-ink-detection/train'\n",
    "    # eval_dir = '/kaggle/input/vesuvius-challenge-ink-detection/test'\n",
    "    # pretrained_weights_filepath = '/kaggle/input/convnextimagenet/convnext_tiny-983f1562.pth',\n",
    "    # output_dir = '/kaggle/working'\n",
    "    # run_eval_sweep=False,\n",
    "    # run_eval_submit=True,\n",
    "    # write_logs=False,\n",
    "    \n",
    "    # # Linux Training\n",
    "    # train_dir='/home/tren/dev/ashenvenus/data/train',\n",
    "    # eval_dir='/home/tren/dev/ashenvenus/data/test',\n",
    "    # output_dir='/home/tren/dev/ashenvenus/output',\n",
    "    # run_eval_sweep=True,\n",
    "    # run_eval_submit=False,\n",
    "    # write_logs=False,\n",
    "    \n",
    "    # Windows Training\n",
    "    train_dir=\"C:\\\\Users\\\\ook\\\\Documents\\\\dev\\\\ashenvenus\\\\data\\\\train\",\n",
    "    eval_dir=\"C:\\\\Users\\\\ook\\\\Documents\\\\dev\\\\ashenvenus\\\\data\\\\test\",\n",
    "    output_dir=\"C:\\\\Users\\\\ook\\\\Documents\\\\dev\\\\ashenvenus\\\\output\",\n",
    "    save_pred_img=True,\n",
    "    save_submit_csv=False,\n",
    "    write_logs=False,\n",
    "    \n",
    "    # Dataset\n",
    "    curriculum='1313',\n",
    "    image_augs=False,\n",
    "    resize_ratio=0.25,\n",
    "    num_workers=0,\n",
    "    max_samples_per_dataset=100,\n",
    "    # Model and training\n",
    "    model='convnext_tiny',\n",
    "    freeze_backbone=True,\n",
    "    optimizer='adam',\n",
    "    lr_scheduling_gamma=0.9,\n",
    "    slice_depth=65,\n",
    "    patch_size_x=224,\n",
    "    patch_size_y=224,\n",
    "    batch_size=64,\n",
    "    lr=0.001,\n",
    "    num_epochs=2,\n",
    "    max_time_hours=8,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ashenvenus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
